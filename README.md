# ðŸ“¦ GyanaSetu(Offline AI Tutor) â€” Submission Instructions





---

## ðŸ”§ 1. How to Run the Offline Tutor Locally

ðŸ“„ See: `Code/Instructions.txt`

That file explains:
- How to download the model using `download_assets.py`
- How to run inference via `llama.cpp`
- How to launch the Flask UI
- How to build `llama.cpp` using `setup_llama.sh`

---

## ðŸ’» 2. Source Code

ðŸ“‚ Location: `Code/`

Includes:
- `finetune_sloth.py` â€” Script to fine-tune the model with your educational dataset
- `quantize.sh` â€” Script to quantize to GGUF using `llama.cpp`
- `download_assets.py` â€” Pulls model files (GGUF, LoRA, tokenizer) from Hugging Face
- `chat_interface.py` â€” Flask-based chat interface
- `setup_llama.sh` â€” Builds and copies `llama.cpp` binaries
- `llama_cpp_bin/` â€” Includes compiled `main` and `quantize` executables

---

## ðŸ“± 2. Flutter Mobile App UI

ðŸ“‚ Location: `Flutter_UI_Scaffold/`

- Basic Flutter chat interface scaffold
- To run:
  flutter pub get
  flutter run

This is currently a UI-only prototype (ready for FFI integration with llama.cpp).

---

## ðŸ”— 5. Resources

ðŸ“‚ Location: `Resources/`

- `huggingface_links.txt` â€” Links to your model and dataset repos on Hugging Face
- `model_card.md` â€” Info on the fine-tuned Gemma-3N GGUF model
- `dataset_card.md` â€” Info on your educational dataset
- `screenshots/` â€” UI + REPL preview images
- `licenses/` â€” Licenses for model and dataset

---

## ðŸ§  Optional: Re-Fine-Tuning or Re-Quantizing

Detailed in:
ðŸ“„ `Code/Instructions.txt`, Section 9  
Use this if you wish to retrain or re-quantize the model using your dataset.

---

If you face any issues, start from `Code/setup_llama.sh` to rebuild binaries and follow instructions step-by-step from there.

Thank you!
